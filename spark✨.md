# Machine-learning-with-apache-spark‚ú®

## Getting started 

**Importing Libraries**
```py
# FindSpark simplifies the process of using Apache Spark with Python

import findspark
findspark.init()

# import SparkSession
from pyspark.sql import SparkSession
```

Notes:
- SparkContext ‚Äî —ç—Ç–æ "—Å—Ç–∞—Ä—ã–π —Å–ø–æ—Å–æ–±" –Ω–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å–æ Spark, –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –∫–ª–∞—Å—Ç–µ—Ä—É –∏ —É–ø—Ä–∞–≤–ª—è—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏—è–º–∏, –Ω–æ —Å–∞–º –ø–æ —Å–µ–±–µ –Ω–µ –≤–∫–ª—é—á–∞–µ—Ç —Ä–∞–±–æ—Ç—É —Å DataFrame –∏ SQL.
- SparkSession ‚Äî —ç—Ç–æ "–Ω–æ–≤—ã–π –∏ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–±", –ø–æ—è–≤–∏–≤—à–∏–π—Å—è –Ω–∞—á–∏–Ω–∞—è —Å Spark 2.0, –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤ —Å–µ–±–µ SparkContext, SQLContext –∏ HiveContext. –¢–æ –µ—Å—Ç—å –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å RDD (–∫–∞–∫ SparkContext), –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å DataFrame, SQL, Hive, Parquet –∏ —Ç.–ø.
- findspark –Ω—É–∂–µ–Ω, –µ—Å–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è SPARK_HOME –∏ PYTHONPATH –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã. –ù–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ –≤ Jupyter Notebook –ª–æ–∫–∞–ª—å–Ω–æ, –∫–æ–≥–¥–∞ PySpark –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏. –ù–µ –Ω—É–∂–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π —Å—Ä–µ–¥–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, Databricks, EMR, Docker, –∏–ª–∏ –≤–Ω—É—Ç—Ä–∏ PySpark-–∫–ª–∞—Å—Ç–µ—Ä–∞) –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è PySpark –∏–∑ pip (pip install pyspark).


```py
# create spark session
spark = SparkSession.builder.appName("Diamond data analysis").getOrCreate()

# load data
# !wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/diamonds.csv

# data to a df
diamond_data = spark.read.csv("diamonds.csv", header=True, inferSchema=True)

# explore data
diamond_data.printSchema()
diamond_data.head(5)
diamond_data.show(5)

# stop the spark session
spark.stop()
```

## Regression


| Built-in Model                            |`pyspark.ml.regression` | 
| -------------------------------- | ------------------------------- | 
| üí° Linear Regression             | `LinearRegression`              | 
| üå≤ Decision Tree Regressor       | `DecisionTreeRegressor`         | 
| üå≥ Random Forest Regressor       | `RandomForestRegressor`         | 
| üéØ GBT Regressor (Boosting)      | `GBTRegressor`                  | 
| ü§ñ AFT Survival Regression       | `AFTSurvivalRegression`         | 
| üßÆ Generalized Linear Regression | `GeneralizedLinearRegression`   |

Notes:
- Spark ML —Ç—Ä–µ–±—É–µ—Ç, —á—Ç–æ–±—ã –≤—Å–µ –≤—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –±—ã–ª–∏ –≤ –æ–¥–Ω–æ–º —Å—Ç–æ–ª–±—Ü–µ —Ç–∏–ø–∞ Vector, –∞ –Ω–µ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö

| üìè Metric       | `.setMetricName()` value | Description                                                                     |
| --------------- | ------------------------ | ------------------------------------------------------------------------------- |
| üßÆ **RMSE**     | `"rmse"`                 | Root Mean Squared Error ‚Äì penalizes large errors more heavily.                  |
| ‚ûï **MSE**       | `"mse"`                  | Mean Squared Error ‚Äì average squared difference between predicted and actual.   |
| ‚ûñ **MAE**       | `"mae"`                  | Mean Absolute Error ‚Äì average absolute difference between predicted and actual. |
| üìà **R¬≤ Score** | `"r2"`                   | Coefficient of Determination ‚Äì proportion of variance explained by the model.   |


### Linear regression

Let's use `diamond_data` from the previous section:

```py

from pyspark.ml.feature import VectorAssembler
from pyspark.ml.regression import LinearRegression, GBTRegressor
from pyspark.ml.evaluation import RegressionEvaluator

# Prepare feature vector
assembler = VectorAssembler(inputCols=["carat", "depth", "table"], outputCol="features")
diamond_transformed_data = assembler.transform(diamond_data)

# Print the vectorized features and label columns
diamond_transformed_data.select("features","price").show()

# Train-test split
(training_data, testing_data) = diamond_transformed_data.randomSplit([0.7, 0.3], seed=42)

# Train LR model
lr = LinearRegression(featuresCol="features", labelCol="price")
model = lr.fit(training_data)

# Make prediction
predictions = model.transform(testing_data)

# Print metrics
metrics = {}
for metric in ['r2', 'mae', 'rmse']:
    evaluator = RegressionEvaluator(labelCol="price", predictionCol="prediction", metricName=metric)
    metrics[metric] = evaluator.evaluate(predictions)
print(metrics)

```

### GBT
```oy
from pyspark.ml.regression import GBTRegressor

gbt = GBTRegressor(featuresCol="features", labelCol="price")
model = gbt.fit(training_data)
predictions = model.transform(testing_data)

metrics = {}
for metric in ['r2', 'mae', 'rmse']:
    evaluator = RegressionEvaluator(labelCol="price", predictionCol="prediction", metricName=metric)
    metrics[metric] = evaluator.evaluate(predictions)
print(metrics)

```


### LightGBM

*Works in theory

```py
!pip install synapseml

from pyspark.sql import SparkSession

from pyspark.ml.feature import VectorAssembler
from pyspark.ml.evaluation import RegressionEvaluator

from synapse.ml.lightgbm import LightGBMRegressor

spark = SparkSession.builder \
    .appName("LightGBM with SynapseML") \
    .config("spark.jars.packages", "com.microsoft.azure:synapseml_2.12:0.11.2") \
    .getOrCreate()

# MOAR RESOURCES, MOAAAR
#spark = SparkSession.builder \
#    .appName("SynapseML Example") \
#    .config("spark.jars.packages", "com.microsoft.azure:synapseml_2.12:0.11.2") \
#    .config("spark.executor.memory", "2g") \
#    .config("spark.driver.memory", "2g") \
#    .getOrCreate()

!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/diamonds.csv
diamond_data = spark.read.csv("diamonds.csv", header=True, inferSchema=True)

assembler = VectorAssembler(inputCols=["carat", "depth", "table"], outputCol="features")
diamond_transformed_data = assembler.transform(diamond_data)
(training_data, testing_data) = diamond_transformed_data.randomSplit([0.7, 0.3], seed=42)

lgbm = LightGBMRegressor(
    featuresCol="features",
    labelCol="price",
    # numIterations=100, learningRate=0.1, numLeaves=31
)

model = lgbm.fit(train_data)
predictions = model.transform(testing_data)
metrics = {}
for metric in ['r2', 'mae', 'rmse']:
    evaluator = RegressionEvaluator(labelCol="price", predictionCol="prediction", metricName=metric)
    metrics[metric] = evaluator.evaluate(predictions)
print(metrics)
```

## Classification

| Model                      | `pyspark.ml.classification`              | Task Type          | Notes                                            |
| ----------------------------- | -------------------------------- | --------------------- | --------------------------------------------------- |
| üìà Logistic Regression   | `LogisticRegression`             | Binary / Multiclass   | Supports regularization, baseline model             |
| ‚öñÔ∏è Linear SVM             | `LinearSVC`                      | Binary only           | No probability outputs, fast and scalable           |
| üìä Naive Bayes            | `NaiveBayes`                     | Binary / Multiclass   | Good for categorical/text data                      |
| üå≥ Decision Tree          | `DecisionTreeClassifier`         | Binary / Multiclass   | Interpretable, prone to overfitting                 |
| üå≤ Random Forest          | `RandomForestClassifier`         | Binary / Multiclass   | Robust, good default ensemble                       |
| üî• Gradient-Boosted Trees | `GBTClassifier`                  | Binary only           | Powerful, but no multiclass support                 |
| üß© One-vs-Rest            | `OneVsRest`                      | Multiclass via binary | Wraps binary classifiers for multiclass             |
| üß† Multilayer Perceptron  | `MultilayerPerceptronClassifier` | Binary / Multiclass   | Simple feedforward neural net                       |
| üßÆ Factorization Machines | `FMClassifier`                   | Binary only           | Great for sparse feature data (e.g. CTR prediction) |

### MulticlassClassificationEvaluator

| Metric        | `.setMetricName()` value | Description                                            |
| ---------------- | ------------------------ | ------------------------------------------------------ |
| üßÆ **Accuracy**  | `"accuracy"`             | Proportion of correct predictions (macro average).     |
| üìê **F1 Score**  | `"f1"`                   | Harmonic mean of precision and recall (macro average). |
| üéØ **Precision** | `"weightedPrecision"`    | Precision weighted by class frequencies.               |
| üéØ **Recall**    | `"weightedRecall"`       | Recall weighted by class frequencies.                  |

## Metrics 

| üì¶ Evaluator Class                     | üß† Task Type                 | üìè Supported Metrics (`.setMetricName()`)                       | üîé Description                                                          |
| -------------------------------------- | ---------------------------- | --------------------------------------------------------------- | ----------------------------------------------------------------------- |
| üßÆ `MulticlassClassificationEvaluator` | Classification (multi-class) | `"accuracy"`, `"f1"`, `"weightedPrecision"`, `"weightedRecall"` | Evaluates multi-class classification models.                            |
| ‚úÖ `BinaryClassificationEvaluator`      | Classification (binary)      | `"areaUnderROC"`, `"areaUnderPR"`                               | Evaluates binary classifiers based on ROC or PR curves.                 |
| üìâ `RegressionEvaluator`               | Regression                   | `"rmse"`, `"mse"`, `"mae"`, `"r2"`                              | Evaluates regression models.                                            |
| üìä `ClusteringEvaluator`               | Clustering                   | `"silhouette"`                                                  | Measures clustering quality using silhouette score (based on distance). |

